{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33386c31",
   "metadata": {},
   "source": [
    "Import Required Libraries & Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee790d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ssudh_o0coipj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>01-02-2015</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
       "      <td>01-05-2015</td>\n",
       "      <td>hong kong stocks open 0.66 percent lower</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
       "      <td>01-06-2015</td>\n",
       "      <td>asian stocks sink euro near nine year</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
       "      <td>01-06-2015</td>\n",
       "      <td>us oil prices slip below 50 a barr</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article        Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b...  01-01-2015   \n",
       "1  HONG KONG: Asian markets started 2015 on an up...  01-02-2015   \n",
       "2  HONG KONG:  Hong Kong shares opened 0.66 perce...  01-05-2015   \n",
       "3  HONG KONG: Asian markets tumbled Tuesday follo...  01-06-2015   \n",
       "4  NEW YORK: US oil prices Monday slipped below $...  01-06-2015   \n",
       "\n",
       "                                             Heading  NewsType  \n",
       "0  sindh govt decides to cut public transport far...  business  \n",
       "1                    asia stocks up in new year trad  business  \n",
       "2           hong kong stocks open 0.66 percent lower  business  \n",
       "3             asian stocks sink euro near nine year   business  \n",
       "4                 us oil prices slip below 50 a barr  business  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# download stopwords if not downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\n",
    "    r\"D:\\Anomaly_hypertext_news_detection\\Dataset-20251117T051821Z-1-001\\Dataset\\Articles.csv\",\n",
    "    encoding=\"latin1\"\n",
    ")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451a5afa",
   "metadata": {},
   "source": [
    "Fix Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e8dd2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Article     0\n",
       "Date        0\n",
       "Heading     0\n",
       "NewsType    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "411cd888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Articles with empty string\n",
    "df['Article'] = df['Article'].fillna(\"\")\n",
    "\n",
    "# Drop rows where both Heading and Article are empty\n",
    "df = df[~((df['Heading'].isna()) & (df['Article']==\"\"))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4997108",
   "metadata": {},
   "source": [
    "Normalize Text (Lowercase + Remove Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99264a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(text):\n",
    "    text = str(text).lower()                               # lowercase\n",
    "    text = re.sub(r'\\d+', '', text)                       # remove numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)               # remove symbols\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()              # remove extra spaces\n",
    "    return text\n",
    "\n",
    "df['clean_basic'] = df['Article'].apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e4137fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>clean_basic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>karachi the sindh government has decided to br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>01-02-2015</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets started on an upswing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
       "      <td>01-05-2015</td>\n",
       "      <td>hong kong stocks open 0.66 percent lower</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong hong kong shares opened percent lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
       "      <td>01-06-2015</td>\n",
       "      <td>asian stocks sink euro near nine year</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets tumbled tuesday follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
       "      <td>01-06-2015</td>\n",
       "      <td>us oil prices slip below 50 a barr</td>\n",
       "      <td>business</td>\n",
       "      <td>new york us oil prices monday slipped below a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article        Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b...  01-01-2015   \n",
       "1  HONG KONG: Asian markets started 2015 on an up...  01-02-2015   \n",
       "2  HONG KONG:  Hong Kong shares opened 0.66 perce...  01-05-2015   \n",
       "3  HONG KONG: Asian markets tumbled Tuesday follo...  01-06-2015   \n",
       "4  NEW YORK: US oil prices Monday slipped below $...  01-06-2015   \n",
       "\n",
       "                                             Heading  NewsType  \\\n",
       "0  sindh govt decides to cut public transport far...  business   \n",
       "1                    asia stocks up in new year trad  business   \n",
       "2           hong kong stocks open 0.66 percent lower  business   \n",
       "3             asian stocks sink euro near nine year   business   \n",
       "4                 us oil prices slip below 50 a barr  business   \n",
       "\n",
       "                                         clean_basic  \n",
       "0  karachi the sindh government has decided to br...  \n",
       "1  hong kong asian markets started on an upswing ...  \n",
       "2  hong kong hong kong shares opened percent lowe...  \n",
       "3  hong kong asian markets tumbled tuesday follow...  \n",
       "4  new york us oil prices monday slipped below a ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aea6b6",
   "metadata": {},
   "source": [
    "Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "954dd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "df['no_stopwords'] = df['clean_basic'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fc08d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>clean_basic</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>karachi the sindh government has decided to br...</td>\n",
       "      <td>karachi sindh government decided bring public ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>01-02-2015</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets started on an upswing ...</td>\n",
       "      <td>hong kong asian markets started upswing limite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
       "      <td>01-05-2015</td>\n",
       "      <td>hong kong stocks open 0.66 percent lower</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong hong kong shares opened percent lowe...</td>\n",
       "      <td>hong kong hong kong shares opened percent lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
       "      <td>01-06-2015</td>\n",
       "      <td>asian stocks sink euro near nine year</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets tumbled tuesday follow...</td>\n",
       "      <td>hong kong asian markets tumbled tuesday follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
       "      <td>01-06-2015</td>\n",
       "      <td>us oil prices slip below 50 a barr</td>\n",
       "      <td>business</td>\n",
       "      <td>new york us oil prices monday slipped below a ...</td>\n",
       "      <td>new york us oil prices monday slipped barrel f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article        Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b...  01-01-2015   \n",
       "1  HONG KONG: Asian markets started 2015 on an up...  01-02-2015   \n",
       "2  HONG KONG:  Hong Kong shares opened 0.66 perce...  01-05-2015   \n",
       "3  HONG KONG: Asian markets tumbled Tuesday follo...  01-06-2015   \n",
       "4  NEW YORK: US oil prices Monday slipped below $...  01-06-2015   \n",
       "\n",
       "                                             Heading  NewsType  \\\n",
       "0  sindh govt decides to cut public transport far...  business   \n",
       "1                    asia stocks up in new year trad  business   \n",
       "2           hong kong stocks open 0.66 percent lower  business   \n",
       "3             asian stocks sink euro near nine year   business   \n",
       "4                 us oil prices slip below 50 a barr  business   \n",
       "\n",
       "                                         clean_basic  \\\n",
       "0  karachi the sindh government has decided to br...   \n",
       "1  hong kong asian markets started on an upswing ...   \n",
       "2  hong kong hong kong shares opened percent lowe...   \n",
       "3  hong kong asian markets tumbled tuesday follow...   \n",
       "4  new york us oil prices monday slipped below a ...   \n",
       "\n",
       "                                        no_stopwords  \n",
       "0  karachi sindh government decided bring public ...  \n",
       "1  hong kong asian markets started upswing limite...  \n",
       "2  hong kong hong kong shares opened percent lowe...  \n",
       "3  hong kong asian markets tumbled tuesday follow...  \n",
       "4  new york us oil prices monday slipped barrel f...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319c859",
   "metadata": {},
   "source": [
    "Lemmatization (SpaCy NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "637d8829",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "df['lemma_text'] = df['no_stopwords'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac09f0",
   "metadata": {},
   "source": [
    "Create Text-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1a2767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['Article'].apply(lambda x: len(str(x).split()))\n",
    "df['sentence_count'] = df['Article'].apply(lambda x: x.count('.') + 1)\n",
    "df['avg_word_length'] = df['Article'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33227bf7",
   "metadata": {},
   "source": [
    "Detect Numbers Mentioned (Fake news often exaggerates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c55a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['digit_count'] = df['Article'].apply(lambda x: sum(char.isdigit() for char in x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1314c",
   "metadata": {},
   "source": [
    "Detect Emotional / Exaggeration Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3564d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotional_words = [\"breaking\", \"shocking\", \"urgent\", \"panic\", \"exclusive\", \"alert\"]\n",
    "\n",
    "def emotional_score(text):\n",
    "    return sum(text.lower().count(word) for word in emotional_words)\n",
    "\n",
    "df['emotion_score'] = df['Article'].apply(emotional_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc7e92c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>clean_basic</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>emotion_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>karachi the sindh government has decided to br...</td>\n",
       "      <td>karachi sindh government decided bring public ...</td>\n",
       "      <td>karachi sindh government decide bring public t...</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>5.433962</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>01-02-2015</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets started on an upswing ...</td>\n",
       "      <td>hong kong asian markets started upswing limite...</td>\n",
       "      <td>hong kong asian market start upswe limited tra...</td>\n",
       "      <td>736</td>\n",
       "      <td>94</td>\n",
       "      <td>5.487772</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
       "      <td>01-05-2015</td>\n",
       "      <td>hong kong stocks open 0.66 percent lower</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong hong kong shares opened percent lowe...</td>\n",
       "      <td>hong kong hong kong shares opened percent lowe...</td>\n",
       "      <td>hong kong hong kong share open percent lower m...</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>4.864865</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
       "      <td>01-06-2015</td>\n",
       "      <td>asian stocks sink euro near nine year</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets tumbled tuesday follow...</td>\n",
       "      <td>hong kong asian markets tumbled tuesday follow...</td>\n",
       "      <td>hong kong asian market tumble tuesday follow p...</td>\n",
       "      <td>523</td>\n",
       "      <td>46</td>\n",
       "      <td>5.141491</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
       "      <td>01-06-2015</td>\n",
       "      <td>us oil prices slip below 50 a barr</td>\n",
       "      <td>business</td>\n",
       "      <td>new york us oil prices monday slipped below a ...</td>\n",
       "      <td>new york us oil prices monday slipped barrel f...</td>\n",
       "      <td>new york us oil price monday slip barrel first...</td>\n",
       "      <td>606</td>\n",
       "      <td>40</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article        Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b...  01-01-2015   \n",
       "1  HONG KONG: Asian markets started 2015 on an up...  01-02-2015   \n",
       "2  HONG KONG:  Hong Kong shares opened 0.66 perce...  01-05-2015   \n",
       "3  HONG KONG: Asian markets tumbled Tuesday follo...  01-06-2015   \n",
       "4  NEW YORK: US oil prices Monday slipped below $...  01-06-2015   \n",
       "\n",
       "                                             Heading  NewsType  \\\n",
       "0  sindh govt decides to cut public transport far...  business   \n",
       "1                    asia stocks up in new year trad  business   \n",
       "2           hong kong stocks open 0.66 percent lower  business   \n",
       "3             asian stocks sink euro near nine year   business   \n",
       "4                 us oil prices slip below 50 a barr  business   \n",
       "\n",
       "                                         clean_basic  \\\n",
       "0  karachi the sindh government has decided to br...   \n",
       "1  hong kong asian markets started on an upswing ...   \n",
       "2  hong kong hong kong shares opened percent lowe...   \n",
       "3  hong kong asian markets tumbled tuesday follow...   \n",
       "4  new york us oil prices monday slipped below a ...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  karachi sindh government decided bring public ...   \n",
       "1  hong kong asian markets started upswing limite...   \n",
       "2  hong kong hong kong shares opened percent lowe...   \n",
       "3  hong kong asian markets tumbled tuesday follow...   \n",
       "4  new york us oil prices monday slipped barrel f...   \n",
       "\n",
       "                                          lemma_text  word_count  \\\n",
       "0  karachi sindh government decide bring public t...         106   \n",
       "1  hong kong asian market start upswe limited tra...         736   \n",
       "2  hong kong hong kong share open percent lower m...          37   \n",
       "3  hong kong asian market tumble tuesday follow p...         523   \n",
       "4  new york us oil price monday slip barrel first...         606   \n",
       "\n",
       "   sentence_count  avg_word_length  digit_count  emotion_score  \n",
       "0               6         5.433962            3              0  \n",
       "1              94         5.487772          267              0  \n",
       "2               6         4.864865           15              0  \n",
       "3              46         5.141491          109              0  \n",
       "4              40         5.166667           69              0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fda5c6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>clean_basic</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>emotion_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>karachi the sindh government has decided to br...</td>\n",
       "      <td>karachi sindh government decided bring public ...</td>\n",
       "      <td>karachi sindh government decide bring public t...</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>5.433962</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets started on an upswing ...</td>\n",
       "      <td>hong kong asian markets started upswing limite...</td>\n",
       "      <td>hong kong asian market start upswe limited tra...</td>\n",
       "      <td>736</td>\n",
       "      <td>94</td>\n",
       "      <td>5.487772</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>hong kong stocks open 0.66 percent lower</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong hong kong shares opened percent lowe...</td>\n",
       "      <td>hong kong hong kong shares opened percent lowe...</td>\n",
       "      <td>hong kong hong kong share open percent lower m...</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>4.864865</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>asian stocks sink euro near nine year</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets tumbled tuesday follow...</td>\n",
       "      <td>hong kong asian markets tumbled tuesday follow...</td>\n",
       "      <td>hong kong asian market tumble tuesday follow p...</td>\n",
       "      <td>523</td>\n",
       "      <td>46</td>\n",
       "      <td>5.141491</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>us oil prices slip below 50 a barr</td>\n",
       "      <td>business</td>\n",
       "      <td>new york us oil prices monday slipped below a ...</td>\n",
       "      <td>new york us oil prices monday slipped barrel f...</td>\n",
       "      <td>new york us oil price monday slip barrel first...</td>\n",
       "      <td>606</td>\n",
       "      <td>40</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article       Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b... 2015-01-01   \n",
       "1  HONG KONG: Asian markets started 2015 on an up... 2015-01-02   \n",
       "2  HONG KONG:  Hong Kong shares opened 0.66 perce... 2015-01-05   \n",
       "3  HONG KONG: Asian markets tumbled Tuesday follo... 2015-01-06   \n",
       "4  NEW YORK: US oil prices Monday slipped below $... 2015-01-06   \n",
       "\n",
       "                                             Heading  NewsType  \\\n",
       "0  sindh govt decides to cut public transport far...  business   \n",
       "1                    asia stocks up in new year trad  business   \n",
       "2           hong kong stocks open 0.66 percent lower  business   \n",
       "3             asian stocks sink euro near nine year   business   \n",
       "4                 us oil prices slip below 50 a barr  business   \n",
       "\n",
       "                                         clean_basic  \\\n",
       "0  karachi the sindh government has decided to br...   \n",
       "1  hong kong asian markets started on an upswing ...   \n",
       "2  hong kong hong kong shares opened percent lowe...   \n",
       "3  hong kong asian markets tumbled tuesday follow...   \n",
       "4  new york us oil prices monday slipped below a ...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  karachi sindh government decided bring public ...   \n",
       "1  hong kong asian markets started upswing limite...   \n",
       "2  hong kong hong kong shares opened percent lowe...   \n",
       "3  hong kong asian markets tumbled tuesday follow...   \n",
       "4  new york us oil prices monday slipped barrel f...   \n",
       "\n",
       "                                          lemma_text  word_count  \\\n",
       "0  karachi sindh government decide bring public t...         106   \n",
       "1  hong kong asian market start upswe limited tra...         736   \n",
       "2  hong kong hong kong share open percent lower m...          37   \n",
       "3  hong kong asian market tumble tuesday follow p...         523   \n",
       "4  new york us oil price monday slip barrel first...         606   \n",
       "\n",
       "   sentence_count  avg_word_length  digit_count  emotion_score  \n",
       "0               6         5.433962            3              0  \n",
       "1              94         5.487772          267              0  \n",
       "2               6         4.864865           15              0  \n",
       "3              46         5.141491          109              0  \n",
       "4              40         5.166667           69              0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b66ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['DayName'] = df['Date'].dt.day_name()          # Monday, Tuesday...\n",
    "df['MonthName'] = df['Date'].dt.month_name()      # January, February...\n",
    "df['Week'] = df['Date'].dt.isocalendar().week      # ISO week number\n",
    "df['Quarter'] = df['Date'].dt.quarter             # Q1, Q2, Q3, Q4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41696570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>clean_basic</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>emotion_score</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayName</th>\n",
       "      <th>MonthName</th>\n",
       "      <th>Week</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>karachi the sindh government has decided to br...</td>\n",
       "      <td>karachi sindh government decided bring public ...</td>\n",
       "      <td>karachi sindh government decide bring public t...</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>5.433962</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets started on an upswing ...</td>\n",
       "      <td>hong kong asian markets started upswing limite...</td>\n",
       "      <td>hong kong asian market start upswe limited tra...</td>\n",
       "      <td>736</td>\n",
       "      <td>94</td>\n",
       "      <td>5.487772</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article       Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b... 2015-01-01   \n",
       "1  HONG KONG: Asian markets started 2015 on an up... 2015-01-02   \n",
       "\n",
       "                                             Heading  NewsType  \\\n",
       "0  sindh govt decides to cut public transport far...  business   \n",
       "1                    asia stocks up in new year trad  business   \n",
       "\n",
       "                                         clean_basic  \\\n",
       "0  karachi the sindh government has decided to br...   \n",
       "1  hong kong asian markets started on an upswing ...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  karachi sindh government decided bring public ...   \n",
       "1  hong kong asian markets started upswing limite...   \n",
       "\n",
       "                                          lemma_text  word_count  \\\n",
       "0  karachi sindh government decide bring public t...         106   \n",
       "1  hong kong asian market start upswe limited tra...         736   \n",
       "\n",
       "   sentence_count  avg_word_length  digit_count  emotion_score    Year  Month  \\\n",
       "0               6         5.433962            3              0  2015.0    1.0   \n",
       "1              94         5.487772          267              0  2015.0    1.0   \n",
       "\n",
       "   Day   DayName MonthName  Week  Quarter  \n",
       "0  1.0  Thursday   January     1      1.0  \n",
       "1  2.0    Friday   January     1      1.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43c6a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclic Encoding (Useful for ML models)\n",
    "\n",
    "# Dates are cyclical — Monday is close to Sunday, and January close to December, but numbers don't reflect that.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df['Month_sin'] = np.sin(2 * np.pi * df['Month']/12)\n",
    "df['Month_cos'] = np.cos(2 * np.pi * df['Month']/12)\n",
    "\n",
    "df['Day_sin'] = np.sin(2 * np.pi * df['Day']/31)\n",
    "df['Day_cos'] = np.cos(2 * np.pi * df['Day']/31)\n",
    "\n",
    "df['Week_sin'] = np.sin(2 * np.pi * df['Week']/52)\n",
    "df['Week_cos'] = np.cos(2 * np.pi * df['Week']/52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a14e53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>clean_basic</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>DayName</th>\n",
       "      <th>MonthName</th>\n",
       "      <th>Week</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "      <th>Week_sin</th>\n",
       "      <th>Week_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>karachi the sindh government has decided to br...</td>\n",
       "      <td>karachi sindh government decided bring public ...</td>\n",
       "      <td>karachi sindh government decide bring public t...</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>5.433962</td>\n",
       "      <td>...</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.979530</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets started on an upswing ...</td>\n",
       "      <td>hong kong asian markets started upswing limite...</td>\n",
       "      <td>hong kong asian market start upswe limited tra...</td>\n",
       "      <td>736</td>\n",
       "      <td>94</td>\n",
       "      <td>5.487772</td>\n",
       "      <td>...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article       Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b... 2015-01-01   \n",
       "1  HONG KONG: Asian markets started 2015 on an up... 2015-01-02   \n",
       "\n",
       "                                             Heading  NewsType  \\\n",
       "0  sindh govt decides to cut public transport far...  business   \n",
       "1                    asia stocks up in new year trad  business   \n",
       "\n",
       "                                         clean_basic  \\\n",
       "0  karachi the sindh government has decided to br...   \n",
       "1  hong kong asian markets started on an upswing ...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  karachi sindh government decided bring public ...   \n",
       "1  hong kong asian markets started upswing limite...   \n",
       "\n",
       "                                          lemma_text  word_count  \\\n",
       "0  karachi sindh government decide bring public t...         106   \n",
       "1  hong kong asian market start upswe limited tra...         736   \n",
       "\n",
       "   sentence_count  avg_word_length  ...   DayName  MonthName  Week  Quarter  \\\n",
       "0               6         5.433962  ...  Thursday    January     1      1.0   \n",
       "1              94         5.487772  ...    Friday    January     1      1.0   \n",
       "\n",
       "   Month_sin Month_cos   Day_sin   Day_cos  Week_sin  Week_cos  \n",
       "0        0.5  0.866025  0.201299  0.979530  0.120537  0.992709  \n",
       "1        0.5  0.866025  0.394356  0.918958  0.120537  0.992709  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c1dfd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special Calendar-Based Features\n",
    "\n",
    "# These help detect events, crisis spikes, or holiday-related news anomalies.\n",
    "df['Is_Weekend'] = df['DayName'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "df['Is_Start_of_Month'] = (df['Day'] <= 3).astype(int)\n",
    "df['Is_End_of_Month'] = (df['Day'] >= 28).astype(int)\n",
    "df['Is_Quarter_Start'] = df['Month'].isin([1, 4, 7, 10]).astype(int)\n",
    "df['Is_Quarter_End'] = df['Month'].isin([3, 6, 9, 12]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f114bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>clean_basic</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "      <th>Week_sin</th>\n",
       "      <th>Week_cos</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Is_Start_of_Month</th>\n",
       "      <th>Is_End_of_Month</th>\n",
       "      <th>Is_Quarter_Start</th>\n",
       "      <th>Is_Quarter_End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>karachi the sindh government has decided to br...</td>\n",
       "      <td>karachi sindh government decided bring public ...</td>\n",
       "      <td>karachi sindh government decide bring public t...</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>5.433962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article       Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b... 2015-01-01   \n",
       "\n",
       "                                             Heading  NewsType  \\\n",
       "0  sindh govt decides to cut public transport far...  business   \n",
       "\n",
       "                                         clean_basic  \\\n",
       "0  karachi the sindh government has decided to br...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  karachi sindh government decided bring public ...   \n",
       "\n",
       "                                          lemma_text  word_count  \\\n",
       "0  karachi sindh government decide bring public t...         106   \n",
       "\n",
       "   sentence_count  avg_word_length  ...  Month_cos   Day_sin  Day_cos  \\\n",
       "0               6         5.433962  ...   0.866025  0.201299  0.97953   \n",
       "\n",
       "   Week_sin  Week_cos Is_Weekend Is_Start_of_Month  Is_End_of_Month  \\\n",
       "0  0.120537  0.992709          0                 1                0   \n",
       "\n",
       "   Is_Quarter_Start  Is_Quarter_End  \n",
       "0                 1               0  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2aa69437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Temporal Features (Important for Anomaly Detection)\n",
    "# Days Since Previous Article \n",
    "df = df.sort_values(by='Date')\n",
    "df['Days_Since_Last'] = df['Date'].diff().dt.days\n",
    "df['Days_Since_Last'] = df['Days_Since_Last'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35f095f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>clean_basic</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "      <th>Week_sin</th>\n",
       "      <th>Week_cos</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Is_Start_of_Month</th>\n",
       "      <th>Is_End_of_Month</th>\n",
       "      <th>Is_Quarter_Start</th>\n",
       "      <th>Is_Quarter_End</th>\n",
       "      <th>Days_Since_Last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>karachi the sindh government has decided to br...</td>\n",
       "      <td>karachi sindh government decided bring public ...</td>\n",
       "      <td>karachi sindh government decide bring public t...</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>5.433962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article       Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b... 2015-01-01   \n",
       "\n",
       "                                             Heading  NewsType  \\\n",
       "0  sindh govt decides to cut public transport far...  business   \n",
       "\n",
       "                                         clean_basic  \\\n",
       "0  karachi the sindh government has decided to br...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  karachi sindh government decided bring public ...   \n",
       "\n",
       "                                          lemma_text  word_count  \\\n",
       "0  karachi sindh government decide bring public t...         106   \n",
       "\n",
       "   sentence_count  avg_word_length  ...   Day_sin  Day_cos  Week_sin  \\\n",
       "0               6         5.433962  ...  0.201299  0.97953  0.120537   \n",
       "\n",
       "   Week_cos  Is_Weekend Is_Start_of_Month Is_End_of_Month  Is_Quarter_Start  \\\n",
       "0  0.992709           0                 1               0                 1   \n",
       "\n",
       "   Is_Quarter_End  Days_Since_Last  \n",
       "0               0              0.0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3826e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publication Frequency per Location / Category (future step — after extracting location) \n",
    "df['Publish_Count_By_Month'] = df.groupby(['Year','Month'])['Article'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b05f80d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2692 entries, 0 to 2691\n",
      "Data columns (total 32 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   Article                 2692 non-null   object        \n",
      " 1   Date                    1164 non-null   datetime64[ns]\n",
      " 2   Heading                 2692 non-null   object        \n",
      " 3   NewsType                2692 non-null   object        \n",
      " 4   clean_basic             2692 non-null   object        \n",
      " 5   no_stopwords            2692 non-null   object        \n",
      " 6   lemma_text              2692 non-null   object        \n",
      " 7   word_count              2692 non-null   int64         \n",
      " 8   sentence_count          2692 non-null   int64         \n",
      " 9   avg_word_length         2692 non-null   float64       \n",
      " 10  digit_count             2692 non-null   int64         \n",
      " 11  emotion_score           2692 non-null   int64         \n",
      " 12  Year                    1164 non-null   float64       \n",
      " 13  Month                   1164 non-null   float64       \n",
      " 14  Day                     1164 non-null   float64       \n",
      " 15  DayName                 1164 non-null   object        \n",
      " 16  MonthName               1164 non-null   object        \n",
      " 17  Week                    1164 non-null   UInt32        \n",
      " 18  Quarter                 1164 non-null   float64       \n",
      " 19  Month_sin               1164 non-null   float64       \n",
      " 20  Month_cos               1164 non-null   float64       \n",
      " 21  Day_sin                 1164 non-null   float64       \n",
      " 22  Day_cos                 1164 non-null   float64       \n",
      " 23  Week_sin                1164 non-null   Float64       \n",
      " 24  Week_cos                1164 non-null   Float64       \n",
      " 25  Is_Weekend              2692 non-null   int32         \n",
      " 26  Is_Start_of_Month       2692 non-null   int32         \n",
      " 27  Is_End_of_Month         2692 non-null   int32         \n",
      " 28  Is_Quarter_Start        2692 non-null   int32         \n",
      " 29  Is_Quarter_End          2692 non-null   int32         \n",
      " 30  Days_Since_Last         2692 non-null   float64       \n",
      " 31  Publish_Count_By_Month  1164 non-null   float64       \n",
      "dtypes: Float64(2), UInt32(1), datetime64[ns](1), float64(11), int32(5), int64(4), object(8)\n",
      "memory usage: 638.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae8711aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>clean_basic</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>Week_sin</th>\n",
       "      <th>Week_cos</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Is_Start_of_Month</th>\n",
       "      <th>Is_End_of_Month</th>\n",
       "      <th>Is_Quarter_Start</th>\n",
       "      <th>Is_Quarter_End</th>\n",
       "      <th>Days_Since_Last</th>\n",
       "      <th>Publish_Count_By_Month</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>karachi the sindh government has decided to br...</td>\n",
       "      <td>karachi sindh government decided bring public ...</td>\n",
       "      <td>karachi sindh government decide bring public t...</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>5.433962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Sindh, Karachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets started on an upswing ...</td>\n",
       "      <td>hong kong asian markets started upswing limite...</td>\n",
       "      <td>hong kong asian market start upswe limited tra...</td>\n",
       "      <td>736</td>\n",
       "      <td>94</td>\n",
       "      <td>5.487772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Singapore, Thailand, Jakarta, Philippines, US,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>hong kong stocks open 0.66 percent lower</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong hong kong shares opened percent lowe...</td>\n",
       "      <td>hong kong hong kong shares opened percent lowe...</td>\n",
       "      <td>hong kong hong kong share open percent lower m...</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>4.864865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239316</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Hong Kong, HONG KONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>asian stocks sink euro near nine year</td>\n",
       "      <td>business</td>\n",
       "      <td>hong kong asian markets tumbled tuesday follow...</td>\n",
       "      <td>hong kong asian markets tumbled tuesday follow...</td>\n",
       "      <td>hong kong asian market tumble tuesday follow p...</td>\n",
       "      <td>523</td>\n",
       "      <td>46</td>\n",
       "      <td>5.141491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239316</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Greece, Athens, Seoul, Milan, Europe, US, Toky...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>us oil prices slip below 50 a barr</td>\n",
       "      <td>business</td>\n",
       "      <td>new york us oil prices monday slipped below a ...</td>\n",
       "      <td>new york us oil prices monday slipped barrel f...</td>\n",
       "      <td>new york us oil price monday slip barrel first...</td>\n",
       "      <td>606</td>\n",
       "      <td>40</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239316</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NEW YORK, Saudi Arabia, Iraq, Vienna, Russia, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article       Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b... 2015-01-01   \n",
       "1  HONG KONG: Asian markets started 2015 on an up... 2015-01-02   \n",
       "2  HONG KONG:  Hong Kong shares opened 0.66 perce... 2015-01-05   \n",
       "3  HONG KONG: Asian markets tumbled Tuesday follo... 2015-01-06   \n",
       "4  NEW YORK: US oil prices Monday slipped below $... 2015-01-06   \n",
       "\n",
       "                                             Heading  NewsType  \\\n",
       "0  sindh govt decides to cut public transport far...  business   \n",
       "1                    asia stocks up in new year trad  business   \n",
       "2           hong kong stocks open 0.66 percent lower  business   \n",
       "3             asian stocks sink euro near nine year   business   \n",
       "4                 us oil prices slip below 50 a barr  business   \n",
       "\n",
       "                                         clean_basic  \\\n",
       "0  karachi the sindh government has decided to br...   \n",
       "1  hong kong asian markets started on an upswing ...   \n",
       "2  hong kong hong kong shares opened percent lowe...   \n",
       "3  hong kong asian markets tumbled tuesday follow...   \n",
       "4  new york us oil prices monday slipped below a ...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  karachi sindh government decided bring public ...   \n",
       "1  hong kong asian markets started upswing limite...   \n",
       "2  hong kong hong kong shares opened percent lowe...   \n",
       "3  hong kong asian markets tumbled tuesday follow...   \n",
       "4  new york us oil prices monday slipped barrel f...   \n",
       "\n",
       "                                          lemma_text  word_count  \\\n",
       "0  karachi sindh government decide bring public t...         106   \n",
       "1  hong kong asian market start upswe limited tra...         736   \n",
       "2  hong kong hong kong share open percent lower m...          37   \n",
       "3  hong kong asian market tumble tuesday follow p...         523   \n",
       "4  new york us oil price monday slip barrel first...         606   \n",
       "\n",
       "   sentence_count  avg_word_length  ...  Week_sin  Week_cos  Is_Weekend  \\\n",
       "0               6         5.433962  ...  0.120537  0.992709           0   \n",
       "1              94         5.487772  ...  0.120537  0.992709           0   \n",
       "2               6         4.864865  ...  0.239316  0.970942           0   \n",
       "3              46         5.141491  ...  0.239316  0.970942           0   \n",
       "4              40         5.166667  ...  0.239316  0.970942           0   \n",
       "\n",
       "   Is_Start_of_Month  Is_End_of_Month Is_Quarter_Start Is_Quarter_End  \\\n",
       "0                  1                0                1              0   \n",
       "1                  1                0                1              0   \n",
       "2                  0                0                1              0   \n",
       "3                  0                0                1              0   \n",
       "4                  0                0                1              0   \n",
       "\n",
       "   Days_Since_Last  Publish_Count_By_Month  \\\n",
       "0              0.0                     8.0   \n",
       "1              1.0                     8.0   \n",
       "2              3.0                     8.0   \n",
       "3              1.0                     8.0   \n",
       "4              0.0                     8.0   \n",
       "\n",
       "                                            Location  \n",
       "0                                     Sindh, Karachi  \n",
       "1  Singapore, Thailand, Jakarta, Philippines, US,...  \n",
       "2                               Hong Kong, HONG KONG  \n",
       "3  Greece, Athens, Seoul, Milan, Europe, US, Toky...  \n",
       "4  NEW YORK, Saudi Arabia, Iraq, Vienna, Russia, ...  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_location(text):\n",
    "    doc = nlp(text)\n",
    "    locations = [ent.text for ent in doc.ents if ent.label_ in ['GPE', 'LOC']]\n",
    "    return ', '.join(set(locations)) if locations else None\n",
    "\n",
    "df[\"Location\"] = df[\"Article\"].apply(extract_location)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1eab6e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>clean_basic</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>Week_sin</th>\n",
       "      <th>Week_cos</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Is_Start_of_Month</th>\n",
       "      <th>Is_End_of_Month</th>\n",
       "      <th>Is_Quarter_Start</th>\n",
       "      <th>Is_Quarter_End</th>\n",
       "      <th>Days_Since_Last</th>\n",
       "      <th>Publish_Count_By_Month</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>karachi the sindh government has decided to br...</td>\n",
       "      <td>karachi sindh government decided bring public ...</td>\n",
       "      <td>karachi sindh government decide bring public t...</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>5.433962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Sindh, Karachi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article       Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b... 2015-01-01   \n",
       "\n",
       "                                             Heading  NewsType  \\\n",
       "0  sindh govt decides to cut public transport far...  business   \n",
       "\n",
       "                                         clean_basic  \\\n",
       "0  karachi the sindh government has decided to br...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  karachi sindh government decided bring public ...   \n",
       "\n",
       "                                          lemma_text  word_count  \\\n",
       "0  karachi sindh government decide bring public t...         106   \n",
       "\n",
       "   sentence_count  avg_word_length  ...  Week_sin  Week_cos  Is_Weekend  \\\n",
       "0               6         5.433962  ...  0.120537  0.992709           0   \n",
       "\n",
       "   Is_Start_of_Month  Is_End_of_Month Is_Quarter_Start Is_Quarter_End  \\\n",
       "0                  1                0                1              0   \n",
       "\n",
       "   Days_Since_Last  Publish_Count_By_Month        Location  \n",
       "0              0.0                     8.0  Sindh, Karachi  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "615c21eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Cleaning: ['Article', 'Date', 'Heading', 'NewsType', 'clean_basic', 'no_stopwords', 'lemma_text', 'word_count', 'sentence_count', 'avg_word_length', 'digit_count', 'emotion_score', 'Year', 'Month', 'Day', 'DayName', 'MonthName', 'Week', 'Quarter', 'Month_sin', 'Month_cos', 'Day_sin', 'Day_cos', 'Week_sin', 'Week_cos', 'Is_Weekend', 'Is_Start_of_Month', 'Is_End_of_Month', 'Is_Quarter_Start', 'Is_Quarter_End', 'Days_Since_Last', 'Publish_Count_By_Month', 'Location']\n",
      "\n",
      "After Cleaning: ['Article', 'Heading', 'NewsType', 'word_count', 'sentence_count', 'avg_word_length', 'digit_count', 'emotion_score', 'Year', 'Month', 'Day', 'Week', 'Quarter', 'Month_sin', 'Month_cos', 'Day_sin', 'Day_cos', 'Week_sin', 'Week_cos', 'Is_Weekend', 'Is_Start_of_Month', 'Is_End_of_Month', 'Is_Quarter_Start', 'Is_Quarter_End', 'Days_Since_Last', 'Publish_Count_By_Month', 'Location', 'full_text']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Show current columns\n",
    "print(\"Before Cleaning:\", df.columns.tolist())\n",
    "\n",
    "# Optional: merge heading + article into a single text field\n",
    "df[\"full_text\"] = df[\"Heading\"].astype(str) + \" \" + df[\"Article\"].astype(str)\n",
    "\n",
    "# Columns to drop\n",
    "columns_to_drop = [\n",
    "    \"Date\", \n",
    "    \"clean_basic\", \n",
    "    \"no_stopwords\", \n",
    "    \"lemma_text\",\n",
    "    \"MonthName\",\n",
    "    \"DayName\",\n",
    "    \"Hour\", \"Minute\", \"Second\"\n",
    "]\n",
    "\n",
    "# Drop columns if present (avoids errors)\n",
    "df = df.drop(columns=[c for c in columns_to_drop if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "print(\"\\nAfter Cleaning:\", df.columns.tolist())\n",
    "\n",
    "# Rearranging columns for final dataset\n",
    "final_column_order = [\n",
    "    \"full_text\", \"Heading\", \"Article\", \"NewsType\",\n",
    "    \"Location\",  \n",
    "    \"digit_count\", \"emotion_score\", \"Sentiment\", \"Readability\",\n",
    "    \"Year\", \"Month\", \"Day\", \"Quarter\", \"Week\", \"Is_Weekend\",\n",
    "    \"Month_sin\", \"Month_cos\", \"Week_sin\", \"Week_cos\",\n",
    "    \"Days_Since_Last\", \"Publish_Count_By_Month\"\n",
    "]\n",
    "\n",
    "df = df[[col for col in final_column_order if col in df.columns]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c25325f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Article</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>Location</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>emotion_score</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Week</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Week_sin</th>\n",
       "      <th>Week_cos</th>\n",
       "      <th>Days_Since_Last</th>\n",
       "      <th>Publish_Count_By_Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>business</td>\n",
       "      <td>Sindh, Karachi</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asia stocks up in new year trad HONG KONG: Asi...</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>business</td>\n",
       "      <td>Singapore, Thailand, Jakarta, Philippines, US,...</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  sindh govt decides to cut public transport far...   \n",
       "1  asia stocks up in new year trad HONG KONG: Asi...   \n",
       "\n",
       "                                             Heading  \\\n",
       "0  sindh govt decides to cut public transport far...   \n",
       "1                    asia stocks up in new year trad   \n",
       "\n",
       "                                             Article  NewsType  \\\n",
       "0  KARACHI: The Sindh government has decided to b...  business   \n",
       "1  HONG KONG: Asian markets started 2015 on an up...  business   \n",
       "\n",
       "                                            Location  digit_count  \\\n",
       "0                                     Sindh, Karachi            3   \n",
       "1  Singapore, Thailand, Jakarta, Philippines, US,...          267   \n",
       "\n",
       "   emotion_score    Year  Month  Day  Quarter  Week  Is_Weekend  Month_sin  \\\n",
       "0              0  2015.0    1.0  1.0      1.0     1           0        0.5   \n",
       "1              0  2015.0    1.0  2.0      1.0     1           0        0.5   \n",
       "\n",
       "   Month_cos  Week_sin  Week_cos  Days_Since_Last  Publish_Count_By_Month  \n",
       "0   0.866025  0.120537  0.992709              0.0                     8.0  \n",
       "1   0.866025  0.120537  0.992709              1.0                     8.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview final dataset\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d83daa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1898b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1,2))\n",
    "tfidf_matrix = tfidf.fit_transform(df['full_text'])\n",
    "\n",
    "df['top_keywords'] = df['full_text'].apply(\n",
    "    lambda x: \", \".join(sorted(tfidf.vocabulary_, key=lambda w: tfidf.vocabulary_[w])[:5])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a76d26e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embedding = model.encode([\"Hello world\"])\n",
    "\n",
    "print(\"Embedding length:\", len(embedding[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf87a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Articles.csv', 'Articles.xlsx']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "sub_path = r\"D:\\Anomaly_hypertext_news_detection\\Dataset-20251117T051821Z-1-001\\Dataset\"\n",
    "print(os.listdir(sub_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "feb8bcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>embedding</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>01-01-2015</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>[0.015569633804261684, 0.05348445102572441, 0....</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article        Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b...  01-01-2015   \n",
       "\n",
       "                                             Heading  NewsType  \\\n",
       "0  sindh govt decides to cut public transport far...  business   \n",
       "\n",
       "                                           embedding  cluster  \n",
       "0  [0.015569633804261684, 0.05348445102572441, 0....        6  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "81beaa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# from sklearn.cluster import KMeans\n",
    "# from transformers import pipeline\n",
    "# import spacy\n",
    "# import tqdm\n",
    "\n",
    "# # -------------------------------\n",
    "# # Assume df already exists\n",
    "# # -------------------------------\n",
    "# text_column = \"Article\" if \"Article\" in df.columns else df.columns[0]\n",
    "\n",
    "# # -------------------------------\n",
    "# # 1️⃣ Embeddings (already done? skip)\n",
    "# # -------------------------------\n",
    "# if \"embedding\" not in df.columns:\n",
    "#     print(\"\\n🔹 Generating Embeddings...\")\n",
    "#     model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "\n",
    "#     texts = df[text_column].fillna(\"\").tolist()\n",
    "\n",
    "#     embeddings = model.encode(\n",
    "#         texts,\n",
    "#         batch_size=32,                # Increased batch = faster\n",
    "#         show_progress_bar=True,\n",
    "#         convert_to_numpy=True\n",
    "#     )\n",
    "\n",
    "#     df[\"embedding\"] = embeddings.tolist()\n",
    "\n",
    "# # -------------------------------\n",
    "# # 2️⃣ Clustering (already done? skip)\n",
    "# # -------------------------------\n",
    "# if \"cluster\" not in df.columns:\n",
    "#     print(\"\\n🔹 Clustering articles...\")\n",
    "#     NUM_CLUSTERS = 8\n",
    "#     kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42)\n",
    "#     df[\"cluster\"] = kmeans.fit_predict(df[\"embedding\"].tolist())\n",
    "\n",
    "# # -------------------------------\n",
    "# # 3️⃣ FAST Zero-Shot Topic Labeling (Batch Mode)\n",
    "# # -------------------------------\n",
    "# print(\"\\n⚡ Assigning topic labels (Optimized Mode)...\")\n",
    "\n",
    "# classifier = pipeline(\n",
    "#     \"zero-shot-classification\",\n",
    "#     model=\"facebook/bart-large-mnli\",   # Much faster and accurate\n",
    "#     device=\"cpu\"\n",
    "# )\n",
    "\n",
    "# candidate_labels = [\n",
    "#     \"politics\", \"sports\", \"technology\", \"crime\",\n",
    "#     \"business\", \"entertainment\", \"health\", \"science\", \"war\"\n",
    "# ]\n",
    "\n",
    "# topics = []\n",
    "# batch_size = 16\n",
    "\n",
    "# for i in tqdm.tqdm(range(0, len(df), batch_size)):\n",
    "#     batch = df[text_column].iloc[i:i+batch_size].fillna(\"\").tolist()\n",
    "\n",
    "#     results = classifier(batch, candidate_labels)\n",
    "\n",
    "#     for res in results:\n",
    "#         topics.append(res[\"labels\"][0])\n",
    "\n",
    "# df[\"topic_label\"] = topics\n",
    "\n",
    "# # -------------------------------\n",
    "# # 4️⃣ Location Extraction\n",
    "# # -------------------------------\n",
    "# print(\"\\n🔹 Extracting locations...\")\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# def extract_location(text):\n",
    "#     doc = nlp(str(text))\n",
    "#     locs = [ent.text for ent in doc.ents if ent.label_ in [\"GPE\", \"LOC\"]]\n",
    "#     return locs[0] if locs else \"Unknown\"\n",
    "\n",
    "# df[\"location\"] = df[text_column].apply(extract_location)\n",
    "\n",
    "# # -------------------------------\n",
    "# # 5️⃣ Save File\n",
    "# # -------------------------------\n",
    "# output_path = r\"D:\\Anomaly_hypertext_news_detection\\Dataset-20251117T051821Z-1-001\\Dataset\\Cleaned_Dataset.csv\"\n",
    "# df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# print(\"\\n✅ Completed Successfully!\")\n",
    "# print(f\"📁 File saved at:\\n➡ {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a14e5af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Article', 'Date', 'Heading', 'NewsType', 'embedding', 'cluster'], dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da1e3da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Using text column: Article\n",
      "📌 Loading lightweight topic classifier...\n",
      "🔍 Model labels: {0: 'arts_&_culture', 1: 'business_&_entrepreneurs', 2: 'celebrity_&_pop_culture', 3: 'diaries_&_daily_life', 4: 'family', 5: 'fashion_&_style', 6: 'film_tv_&_video', 7: 'fitness_&_health', 8: 'food_&_dining', 9: 'gaming', 10: 'learning_&_educational', 11: 'music', 12: 'news_&_social_concern', 13: 'other_hobbies', 14: 'relationships', 15: 'science_&_technology', 16: 'sports', 17: 'travel_&_adventure', 18: 'youth_&_student_life'}\n",
      "⚡ Assigning topics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2692/2692 [06:46<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Topic labeling completed!\n",
      "💾 Saved as cleaned_final_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "# Auto detect text column\n",
    "possible_cols = [\"cleaned_text\", \"text\", \"content\", \"article\", \"body\", \"news\", \"processed_text\"]\n",
    "text_column = None\n",
    "\n",
    "for col in df.columns:\n",
    "    if col.lower() in possible_cols:\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "if text_column is None:\n",
    "    raise Exception(\"❌ No valid text column found. Please rename your text column to 'cleaned_text' or tell me its name.\")\n",
    "\n",
    "print(f\"📌 Using text column: {text_column}\")\n",
    "\n",
    "print(\"📌 Loading lightweight topic classifier...\")\n",
    "model_name = \"cardiffnlp/tweet-topic-21-multi\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(\"cpu\")\n",
    "\n",
    "labels = model.config.id2label\n",
    "print(\"🔍 Model labels:\", labels)\n",
    "\n",
    "def classify_topic(text):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=256)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    scores = torch.softmax(output.logits, dim=1).numpy()[0]\n",
    "    return labels[int(np.argmax(scores))]\n",
    "\n",
    "print(\"⚡ Assigning topics...\")\n",
    "\n",
    "df[\"topic_label\"] = [\n",
    "    classify_topic(text) if isinstance(text, str) and text.strip() else \"Unknown\"\n",
    "    for text in tqdm.tqdm(df[text_column])\n",
    "]\n",
    "\n",
    "print(\"🎉 Topic labeling completed!\")\n",
    "\n",
    "# Save\n",
    "df.to_csv(\"cleaned_final_dataset.csv\", index=False)\n",
    "print(\"💾 Saved as cleaned_final_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5cc8ecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 1.26.4\n",
      "Torch: 2.9.1+cpu\n",
      "Tensor → NumPy test: [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Tensor → NumPy test:\", torch.tensor([1,2,3]).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22d8f3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 50000/50000 [00:16<00:00, 3052.34 examples/s]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\Anomaly_hypertext_news_detection\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1636: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssudh_o0coipj\\AppData\\Local\\Temp\\ipykernel_24892\\1588732567.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 5:26:12, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 06:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 4.059545517520746e-06, 'eval_accuracy': 1.0, 'eval_runtime': 397.4412, 'eval_samples_per_second': 2.516, 'eval_steps_per_second': 0.315, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import accelerate\n",
    "print(accelerate.__version__)\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_ds = dataset.map(tokenize, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Metric\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Training Settings (FIXED: removed unsupported evaluation_strategy)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./news_class_model\",\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=20,\n",
    "    save_steps=1000,\n",
    "    no_cuda=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"].select(range(5000)),  # Smaller subset for CPU\n",
    "    eval_dataset=tokenized_ds[\"test\"].select(range(1000)),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Manual evaluation (since old version doesn't auto_eval)\n",
    "print(\"\\nEvaluating model...\")\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2da315ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cleaning.ipynb', 'news_class_model']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acadc6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['checkpoint-1000', 'checkpoint-1250']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(\"news_class_model\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0de74bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully to: news_class_model_final\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "checkpoint = \"news_class_model/checkpoint-1250\"\n",
    "save_dir = \"news_class_model_final\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "model.save_pretrained(save_dir)\n",
    "\n",
    "print(\"Model saved successfully to:\", save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9bbee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9999954700469971}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"news_class_model_final\",\n",
    "    tokenizer=\"news_class_model_final\",\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "text = \"India reports major breakthrough in science and technology...\"\n",
    "result = classifier(text)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de49590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Apple releases new AI powered chip for iPhones.', 'labels': ['technology', 'business', 'crime', 'science', 'sports', 'war', 'politics', 'health', 'entertainment'], 'scores': [0.3246600925922394, 0.16670523583889008, 0.11062277853488922, 0.10744946449995041, 0.08850058913230896, 0.07212882488965988, 0.05216379091143608, 0.0392000637948513, 0.03856910765171051]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"joeddav/xlm-roberta-large-xnli\"\n",
    ")\n",
    "\n",
    "candidate_labels = [\n",
    "    \"politics\", \"sports\", \"technology\", \"crime\", \n",
    "    \"business\", \"entertainment\", \"health\", \"science\", \"war\"\n",
    "]\n",
    "\n",
    "text = \"Apple releases new AI powered chip for iPhones.\"\n",
    "\n",
    "result = classifier(text, candidate_labels)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "897ca714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "hf_cache_dir = \"D:/Anomaly_hypertext_news_detection/hf_cache\"\n",
    "os.environ[\"HF_HOME\"] = hf_cache_dir          # Hugging Face main cache\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = hf_cache_dir\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = hf_cache_dir\n",
    "os.environ[\"HF_METRICS_CACHE\"] = hf_cache_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4867ba42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted News Type: war or conflict (score: 0.42)\n",
      "Predicted Sentiment: Positive (compound score: 0.4019)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ News Type Classification\n",
    "# -----------------------------\n",
    "# HF token optional if model is public\n",
    "hf_token = \"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\"  # Optional if model is public\n",
    "\n",
    "news_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"MoritzLaurer/deberta-v3-base-mnli\",\n",
    "    use_auth_token=hf_token,  # optional\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "# Candidate labels for News Type\n",
    "candidate_labels = [\n",
    "    \"technology news\", \n",
    "    \"sports news\", \n",
    "    \"political news\", \n",
    "    \"crime report\", \n",
    "    \"entertainment news\",\n",
    "    \"financial/business news\",\n",
    "    \"health and medicine\",\n",
    "    \"science discovery\",\n",
    "    \"war or conflict\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Sentiment Analysis (VADER)\n",
    "# -----------------------------\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Example Article\n",
    "# -----------------------------\n",
    "article = \"Apple releases new AI-powered chip for iPhones, promising faster performance.\"\n",
    "\n",
    "# Predict News Type\n",
    "news_result = news_classifier(article, candidate_labels)\n",
    "news_type = news_result['labels'][0]\n",
    "news_score = news_result['scores'][0]\n",
    "\n",
    "# Predict Sentiment\n",
    "scores = sentiment_analyzer.polarity_scores(article)\n",
    "compound = scores['compound']\n",
    "\n",
    "if compound >= 0.05:\n",
    "    sentiment_label = \"Positive\"\n",
    "elif compound <= -0.05:\n",
    "    sentiment_label = \"Negative\"\n",
    "else:\n",
    "    sentiment_label = \"Neutral\"\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Display Results\n",
    "# -----------------------------\n",
    "print(f\"Predicted News Type: {news_type} (score: {news_score:.2f})\")\n",
    "print(f\"Predicted Sentiment: {sentiment_label} (compound score: {compound})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4af6264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Apple releases new AI-powered chip for iPhones, promising faster performance.\n",
      "Predicted News Type: technology news (score: 0.43)\n",
      "Predicted Sentiment: Positive (compound score: 0.4019)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Hugging Face Token (Optional if model is public)\n",
    "# -----------------------------\n",
    "hf_token = \"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\"\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Zero-Shot News Type Classification\n",
    "# -----------------------------\n",
    "news_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"MoritzLaurer/deberta-v3-base-mnli\",\n",
    "    use_auth_token=hf_token,  # optional\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "# Refined candidate labels\n",
    "candidate_labels = [\n",
    "    \"technology news\",\n",
    "    \"science news\",\n",
    "    \"business news\",\n",
    "    \"politics news\",\n",
    "    \"sports news\",\n",
    "    \"entertainment news\",\n",
    "    \"health news\",\n",
    "    \"crime news\",\n",
    "    \"environment news\",\n",
    "    \"war or conflict news\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Sentiment Analysis (VADER)\n",
    "# -----------------------------\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Function to Analyze Article\n",
    "# -----------------------------\n",
    "def analyze_article(article_text):\n",
    "    # News Type Prediction\n",
    "    news_result = news_classifier(article_text, candidate_labels)\n",
    "    news_type = news_result['labels'][0]\n",
    "    news_score = news_result['scores'][0]\n",
    "\n",
    "    # Sentiment Prediction\n",
    "    scores = sentiment_analyzer.polarity_scores(article_text)\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        sentiment_label = \"Positive\"\n",
    "    elif compound <= -0.05:\n",
    "        sentiment_label = \"Negative\"\n",
    "    else:\n",
    "        sentiment_label = \"Neutral\"\n",
    "\n",
    "    # Display Results\n",
    "    print(f\"Article: {article_text}\")\n",
    "    print(f\"Predicted News Type: {news_type} (score: {news_score:.2f})\")\n",
    "    print(f\"Predicted Sentiment: {sentiment_label} (compound score: {compound:.4f})\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ Example Usage\n",
    "# -----------------------------\n",
    "article = \"Apple releases new AI-powered chip for iPhones, promising faster performance.\"\n",
    "analyze_article(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00b078ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Apple releases new AI-powered chip for iPhones, promising faster performance.\n",
      "Predicted News Type: war or conflict (score: 0.42)\n",
      "Predicted Sentiment: LABEL_0 (score: 1.00)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "model_path = \"./news_class_model_final\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Load your fine-tuned model\n",
    "# -----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Create a sentiment analysis pipeline using your fine-tuned model\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ News Type Zero-Shot Classifier\n",
    "# -----------------------------\n",
    "hf_token = \"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\"  # Optional if model public\n",
    "news_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"MoritzLaurer/deberta-v3-base-mnli\",\n",
    "    use_auth_token=hf_token,\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "candidate_labels = [\n",
    "    \"technology news\", \n",
    "    \"sports news\", \n",
    "    \"political news\", \n",
    "    \"crime report\", \n",
    "    \"entertainment news\",\n",
    "    \"financial/business news\",\n",
    "    \"health and medicine\",\n",
    "    \"science discovery\",\n",
    "    \"war or conflict\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Example Article\n",
    "# -----------------------------\n",
    "article = \"Apple releases new AI-powered chip for iPhones, promising faster performance.\"\n",
    "\n",
    "# Predict News Type\n",
    "news_result = news_classifier(article, candidate_labels)\n",
    "news_type = news_result['labels'][0]\n",
    "news_score = news_result['scores'][0]\n",
    "\n",
    "# Predict Sentiment\n",
    "sentiment_result = sentiment_analyzer(article)\n",
    "sentiment_label = sentiment_result[0]['label']\n",
    "sentiment_score = sentiment_result[0]['score']\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Display Results\n",
    "# -----------------------------\n",
    "print(f\"Article: {article}\")\n",
    "print(f\"Predicted News Type: {news_type} (score: {news_score:.2f})\")\n",
    "print(f\"Predicted Sentiment: {sentiment_label} (score: {sentiment_score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d08b7ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Apple releases new AI-powered chip for iPhones, promising faster performance.\n",
      "Predicted News Type: war or conflict (score: 0.42)\n",
      "Predicted Sentiment: Negative (score: 1.00)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "model_path = \"./news_class_model_final\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Load your fine-tuned sentiment model\n",
    "# -----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Map label IDs to sentiment names (IMDB style)\n",
    "label_mapping = {0: \"Negative\", 1: \"Positive\"}\n",
    "\n",
    "# Sentiment pipeline\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ News Type Zero-Shot Classifier\n",
    "# -----------------------------\n",
    "hf_token = \"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\"  # optional if model public\n",
    "news_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"MoritzLaurer/deberta-v3-base-mnli\",\n",
    "    use_auth_token=hf_token,\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "candidate_labels = [\n",
    "    \"technology news\", \n",
    "    \"sports news\", \n",
    "    \"political news\", \n",
    "    \"crime report\", \n",
    "    \"entertainment news\",\n",
    "    \"financial/business news\",\n",
    "    \"health and medicine\",\n",
    "    \"science discovery\",\n",
    "    \"war or conflict\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Example Article\n",
    "# -----------------------------\n",
    "article = \"Apple releases new AI-powered chip for iPhones, promising faster performance.\"\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Predict News Type\n",
    "# -----------------------------\n",
    "news_result = news_classifier(article, candidate_labels)\n",
    "news_type = news_result['labels'][0]\n",
    "news_score = news_result['scores'][0]\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ Predict Sentiment\n",
    "# -----------------------------\n",
    "sentiment_result = sentiment_analyzer(article)\n",
    "# Convert LABEL_0 / LABEL_1 to human-readable label\n",
    "pred_label_id = int(sentiment_result[0]['label'].split(\"_\")[1])\n",
    "sentiment_label = label_mapping[pred_label_id]\n",
    "sentiment_score = sentiment_result[0]['score']\n",
    "\n",
    "# -----------------------------\n",
    "# 6️⃣ Display Results\n",
    "# -----------------------------\n",
    "print(f\"Article: {article}\")\n",
    "print(f\"Predicted News Type: {news_type} (score: {news_score:.2f})\")\n",
    "print(f\"Predicted Sentiment: {sentiment_label} (score: {sentiment_score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7676429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Apple releases new AI-powered chip for iPhones, promising faster performance.\n",
      "Predicted News Type: war or conflict (score: 0.42)\n",
      "Predicted Sentiment: Negative (score: 1.00)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "model_path = \"./news_class_model_final\"  # Your fine-tuned sentiment model\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Load Fine-Tuned Sentiment Model\n",
    "# -----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Create sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "# VADER fallback analyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Map numeric labels from your fine-tuned model\n",
    "label_map = {\"LABEL_0\": \"Negative\", \"LABEL_1\": \"Positive\"}\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Load Zero-Shot News Classifier\n",
    "# -----------------------------\n",
    "hf_token = \"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\"  # Optional if model public\n",
    "news_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"MoritzLaurer/deberta-v3-base-mnli\",\n",
    "    use_auth_token=hf_token,\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "candidate_labels = [\n",
    "    \"technology news\", \n",
    "    \"sports news\", \n",
    "    \"political news\", \n",
    "    \"crime report\", \n",
    "    \"entertainment news\",\n",
    "    \"financial/business news\",\n",
    "    \"health and medicine\",\n",
    "    \"science discovery\",\n",
    "    \"war or conflict\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Example Article\n",
    "# -----------------------------\n",
    "article = \"Apple releases new AI-powered chip for iPhones, promising faster performance.\"\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Predict News Type\n",
    "# -----------------------------\n",
    "news_result = news_classifier(article, candidate_labels)\n",
    "news_type = news_result['labels'][0]\n",
    "news_score = news_result['scores'][0]\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ Predict Sentiment\n",
    "# -----------------------------\n",
    "sentiment_result = sentiment_pipeline(article)\n",
    "raw_label = sentiment_result[0]['label']\n",
    "sentiment_label = label_map.get(raw_label, raw_label)\n",
    "sentiment_score = sentiment_result[0]['score']\n",
    "\n",
    "# Use VADER as fallback if confidence is low\n",
    "if sentiment_score < 0.6:\n",
    "    vader_scores = vader_analyzer.polarity_scores(article)\n",
    "    compound = vader_scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        sentiment_label = \"Positive\"\n",
    "    elif compound <= -0.05:\n",
    "        sentiment_label = \"Negative\"\n",
    "    else:\n",
    "        sentiment_label = \"Neutral\"\n",
    "    sentiment_score = compound\n",
    "\n",
    "# -----------------------------\n",
    "# 6️⃣ Display Results\n",
    "# -----------------------------\n",
    "print(f\"Article: {article}\")\n",
    "print(f\"Predicted News Type: {news_type} (score: {news_score:.2f})\")\n",
    "print(f\"Predicted Sentiment: {sentiment_label} (score: {sentiment_score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbdf51c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Apple releases new AI-powered chip for iPhones, promising faster performance.\n",
      "Predicted News Type: technology news (score: 0.56)\n",
      "Predicted Sentiment: Positive (compound score: 0.40)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Hugging Face Zero-Shot Classifier\n",
    "# -----------------------------\n",
    "hf_token = \"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\"  # Optional if model public\n",
    "\n",
    "news_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"MoritzLaurer/deberta-v3-base-mnli\",\n",
    "    use_auth_token=hf_token,\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "# Candidate labels (more relevant to tech/news)\n",
    "candidate_labels = [\n",
    "    \"technology news\", \n",
    "    \"sports news\", \n",
    "    \"political news\", \n",
    "    \"crime report\", \n",
    "    \"entertainment news\",\n",
    "    \"financial/business news\",\n",
    "    \"health and medicine\",\n",
    "    \"science discovery\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Sentiment Analysis (VADER)\n",
    "# -----------------------------\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Example Article\n",
    "# -----------------------------\n",
    "article = \"Apple releases new AI-powered chip for iPhones, promising faster performance.\"\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Predict News Type\n",
    "# -----------------------------\n",
    "news_result = news_classifier(article, candidate_labels)\n",
    "news_type = news_result['labels'][0]\n",
    "news_score = news_result['scores'][0]\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ Predict Sentiment\n",
    "# -----------------------------\n",
    "scores = sentiment_analyzer.polarity_scores(article)\n",
    "compound = scores['compound']\n",
    "\n",
    "if compound >= 0.05:\n",
    "    sentiment_label = \"Positive\"\n",
    "elif compound <= -0.05:\n",
    "    sentiment_label = \"Negative\"\n",
    "else:\n",
    "    sentiment_label = \"Neutral\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6️⃣ Display Results\n",
    "# -----------------------------\n",
    "print(f\"Article: {article}\")\n",
    "print(f\"Predicted News Type: {news_type} (score: {news_score:.2f})\")\n",
    "print(f\"Predicted Sentiment: {sentiment_label} (compound score: {compound:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd289546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Model saved successfully at: D:\\Anomaly_hypertext_news_detection\\Models\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"MoritzLaurer/deberta-v3-base-mnli\"\n",
    "\n",
    "# Load model from HF\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Correct path to save\n",
    "save_path = r\"D:\\Anomaly_hypertext_news_detection\\Models\"\n",
    "\n",
    "# Save model + tokenizer locally\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(\"🎉 Model saved successfully at:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c64a8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from 'D:\\Anomaly_hypertext_news_detection\\Models' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded Locally!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "saved_model_path = r\"D:\\Anomaly_hypertext_news_detection\\Models\"\n",
    "\n",
    "news_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=saved_model_path,\n",
    "    tokenizer=saved_model_path,\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "print(\"Model Loaded Locally!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e229df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anomaly_hypertext_news_detection\\.venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= 📌 NEWS ANALYSIS REPORT =================\n",
      "\n",
      "📰 Text Analyzed: Madhya Pradesh Farmers' Day-Long Protest At Highway Over MSP Suspended\n",
      "\n",
      "📌 Predicted Category: protest news  (Confidence: 0.65)\n",
      "💬 Sentiment: Negative  (VADER Score: -0.6249)\n",
      "🚨 Content Assessment: ⚪ Personal / Non-News Statement\n",
      "🔍 Similarity Score: 0.005\n",
      "⚠ Anomaly Score: 1.000\n",
      "📌 Overall Status: 🔴 Highly Deviating / Possibly Fake\n",
      "📘 Multi-Perspective Categories: [('protest news', 0.6504061818122864), ('travel news', 0.09086829423904419), ('political/social news', 0.08618099242448807), ('financial/business news', 0.05310504138469696), ('political news', 0.04636052995920181), ('technology news', 0.016080709174275398), ('breaking news', 0.012706955894827843), ('health and medicine', 0.008851170539855957), ('crime report', 0.007686261087656021), ('environmental news', 0.006726773921400309), ('science discovery', 0.0060768332332372665), ('disaster news', 0.005817578174173832), ('entertainment news', 0.005346919875591993), ('sports news', 0.003785741049796343)]\n",
      "\n",
      "===========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 📰 Advanced News Analysis Script\n",
    "# ==============================\n",
    "\n",
    "from transformers import pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ----------------------------\n",
    "# 1️⃣ ZERO-SHOT MULTI-CATEGORY MODEL\n",
    "# ----------------------------\n",
    "hf_token = \"#######################\"\n",
    "\n",
    "news_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"MoritzLaurer/deberta-v3-base-mnli\",\n",
    "    use_auth_token=hf_token,\n",
    "    device=-1  # CPU mode\n",
    ")\n",
    "\n",
    "candidate_labels = [\n",
    "    \"technology news\", \"sports news\", \"political news\", \"crime report\",\n",
    "    \"entertainment news\",\"financial/business news\",\n",
    "    \"health and medicine\",\"science discovery\",\"travel news\",\n",
    "    \"breaking news\",\"disaster news\",\"protest news\",\n",
    "    \"environmental news\",\"political/social news\"\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# 2️⃣ SENTIMENT ANALYZER\n",
    "# ----------------------------\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# ----------------------------\n",
    "# 3️⃣ ANOMALY DETECTOR\n",
    "# ----------------------------\n",
    "BASELINE_PATH = r\"D:\\Anomaly_hypertext_news_detection\\Preprocessing\\cleaned_final_dataset.csv\"\n",
    "\n",
    "class NewsAnomalyDetector:\n",
    "    def __init__(self):\n",
    "        df = pd.read_csv(BASELINE_PATH)\n",
    "        possible_cols = [\"cleaned_text\", \"text\", \"content\", \"article\", \"news\"]\n",
    "        text_col = next((c for c in df.columns if c.lower() in possible_cols), None)\n",
    "        if text_col is None:\n",
    "            raise Exception(\"No usable text column found in CSV\")\n",
    "        self.baseline_news = df[text_col].astype(str).tolist()\n",
    "        self.vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "        self.baseline_vectors = self.vectorizer.fit_transform(self.baseline_news)\n",
    "\n",
    "    def detect(self, article):\n",
    "        article_vector = self.vectorizer.transform([article])\n",
    "        similarity_scores = cosine_similarity(article_vector, self.baseline_vectors).flatten()\n",
    "        avg_similarity = np.mean(similarity_scores)\n",
    "        anomaly_score = 1 - avg_similarity\n",
    "        return anomaly_score, float(avg_similarity)\n",
    "\n",
    "detector = NewsAnomalyDetector()\n",
    "\n",
    "# ----------------------------\n",
    "# 4️⃣ CONTENT TYPE DETECTION\n",
    "# ----------------------------\n",
    "def detect_content_type(article):\n",
    "    if len(article.split()) < 20:\n",
    "        if re.search(r\"[.!?]$\", article.strip()):\n",
    "            return \"🟢 Short News Headline\"\n",
    "        else:\n",
    "            return \"⚪ Personal / Non-News Statement\"\n",
    "    else:\n",
    "        return \"🔵 Normal News Article\"\n",
    "\n",
    "# ----------------------------\n",
    "# 5️⃣ ANOMALY SCORING FUNCTION\n",
    "# ----------------------------\n",
    "def compute_anomaly(article, detector, multi_labels):\n",
    "    base_anomaly, similarity = detector.detect(article)\n",
    "    \n",
    "    # Personal/clickbait detection\n",
    "    personal_keywords = [\"I\", \"my\", \"we\", \"our\", \"us\", \"personal\", \"exclusive\", \"shock\"]\n",
    "    clickbait_factor = 0.05 if any(word.lower() in article.lower() for word in personal_keywords) else 0.0\n",
    "\n",
    "    # Multi-perspective weighting\n",
    "    low_confidence_labels = [score for _, score in multi_labels if score < 0.1]\n",
    "    label_factor = sum(low_confidence_labels) * 0.2\n",
    "\n",
    "    # Final anomaly score\n",
    "    anomaly_score = base_anomaly + clickbait_factor + label_factor\n",
    "    anomaly_score = min(anomaly_score, 1.0)\n",
    "\n",
    "    # Map to overall status\n",
    "    if anomaly_score <= 0.3:\n",
    "        status = \"🟢 Normal News\"\n",
    "    elif anomaly_score <= 0.6:\n",
    "        status = \"🟡 Rare / Needs Review\"\n",
    "    elif anomaly_score <= 0.85:\n",
    "        status = \"🔵 Unusual / Rare Event\"\n",
    "    else:\n",
    "        status = \"🔴 Highly Deviating / Possibly Fake\"\n",
    "\n",
    "    return anomaly_score, similarity, status\n",
    "\n",
    "# ----------------------------\n",
    "# 6️⃣ USER INPUT\n",
    "# ----------------------------\n",
    "article = input(\"\\nEnter News Article:\\n\")\n",
    "\n",
    "# ----------------------------\n",
    "# 7️⃣ CATEGORY PREDICTION\n",
    "# ----------------------------\n",
    "news_result = news_classifier(article, candidate_labels)\n",
    "multi_labels = list(zip(news_result['labels'], news_result['scores']))\n",
    "predicted_type = multi_labels[0][0]\n",
    "confidence = round(multi_labels[0][1], 3)\n",
    "\n",
    "# ----------------------------\n",
    "# 8️⃣ SENTIMENT ANALYSIS\n",
    "# ----------------------------\n",
    "sentiment_scores = sentiment_analyzer.polarity_scores(article)\n",
    "compound_score = sentiment_scores['compound']\n",
    "\n",
    "if compound_score >= 0.05:\n",
    "    sentiment_label = \"Positive\"\n",
    "elif compound_score <= -0.05:\n",
    "    sentiment_label = \"Negative\"\n",
    "else:\n",
    "    sentiment_label = \"Neutral\"\n",
    "\n",
    "# ----------------------------\n",
    "# 9️⃣ CONTENT TYPE\n",
    "# ----------------------------\n",
    "content_type = detect_content_type(article)\n",
    "\n",
    "# ----------------------------\n",
    "# 🔟 ANOMALY SCORING\n",
    "# ----------------------------\n",
    "anomaly_score, similarity_score, overall_status = compute_anomaly(article, detector, multi_labels)\n",
    "\n",
    "# ----------------------------\n",
    "# 1️⃣1️⃣ FINAL REPORT\n",
    "# ----------------------------\n",
    "print(\"\\n================= 📌 NEWS ANALYSIS REPORT =================\\n\")\n",
    "print(f\"📰 Text Analyzed: {article}\\n\")\n",
    "print(f\"📌 Predicted Category: {predicted_type}  (Confidence: {confidence})\")\n",
    "print(f\"💬 Sentiment: {sentiment_label}  (VADER Score: {compound_score})\")\n",
    "print(f\"🚨 Content Assessment: {content_type}\")\n",
    "print(f\"🔍 Similarity Score: {similarity_score:.3f}\")\n",
    "print(f\"⚠ Anomaly Score: {anomaly_score:.3f}\")\n",
    "print(f\"📌 Overall Status: {overall_status}\")\n",
    "print(f\"📘 Multi-Perspective Categories: {multi_labels}\")\n",
    "print(\"\\n===========================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 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"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
